{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO3Ja4mnmX1AQSTNw7LWO/k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjib7777/-Hyperspectral-Image-Classification/blob/main/Pavia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxYbkhizjZuK",
        "outputId": "a0d627c2-18df-4fbd-c19a-9bf3f7891481"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.4.26)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.utils import dense_to_sparse\n",
        "from sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "um32xHeSj67o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzbAbpCS0ScX",
        "outputId": "00844351-7c20-48a3-badf-1668633e8641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pavia_university():\n",
        "    data = sio.loadmat('PaviaU.mat')['paviaU']\n",
        "    labels = sio.loadmat('PaviaU_gt.mat')['paviaU_gt']\n",
        "    return data, labels\n",
        "\n",
        "def preprocess(data):\n",
        "    data = data.astype(np.float32)\n",
        "    data -= np.min(data)\n",
        "    data /= np.max(data)\n",
        "    return data\n",
        "\n",
        "def apply_pca(data, num_components=30):\n",
        "    h, w, c = data.shape\n",
        "    reshaped = data.reshape(-1, c)\n",
        "    pca = PCA(n_components=num_components)\n",
        "    reduced = pca.fit_transform(reshaped)\n",
        "    return reduced.reshape(h, w, num_components)\n",
        "\n",
        "def extract_patches(data, labels, patch_size=7):\n",
        "    margin = patch_size // 2\n",
        "    padded_data = np.pad(data, ((margin, margin), (margin, margin), (0, 0)), mode='constant')\n",
        "    h, w, c = data.shape\n",
        "    patches, targets, indices = [], [], []\n",
        "    for i in range(h):\n",
        "        for j in range(w):\n",
        "            if labels[i, j] == 0:\n",
        "                continue\n",
        "            patch = padded_data[i:i+patch_size, j:j+patch_size, :]\n",
        "            patches.append(patch)\n",
        "            targets.append(labels[i, j])\n",
        "            indices.append((i, j))\n",
        "    return np.array(patches), np.array(targets), np.array(indices)"
      ],
      "metadata": {
        "id": "RiNbu_d-j8xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HSIDataset(Dataset):\n",
        "    def __init__(self, x_img, x_graph, y):\n",
        "        self.x_img = x_img\n",
        "        self.x_graph = x_graph\n",
        "        self.y = y\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x_img[idx], self.x_graph[idx], self.y[idx]\n",
        "\n",
        "class SpectralSpatialCNN(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super().__init__()\n",
        "        self.conv3d = nn.Sequential(\n",
        "            nn.Conv3d(1, 8, kernel_size=(3, 3, 3), padding=1),\n",
        "            nn.BatchNorm3d(8),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv3d(8, 16, kernel_size=(3, 3, 3), padding=1),\n",
        "            nn.BatchNorm3d(16),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        with torch.no_grad():\n",
        "            dummy = torch.zeros(1, 1, 7, 7, in_channels)\n",
        "            out = self.conv3d(dummy)\n",
        "            self.flattened = out.view(1, -1).shape[1]\n",
        "        self.fc = nn.Linear(self.flattened, 128)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.conv3d(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "Miyk1aCnkPDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCNBranch(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 64)\n",
        "        self.conv2 = GCNConv(64, 128)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, 0.3, training=self.training)\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        return x\n",
        "\n",
        "class DualBranchFusion(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "        self.branch1 = SpectralSpatialCNN(in_channels)\n",
        "        self.branch2 = GCNBranch(in_channels)\n",
        "        self.attn = nn.Sequential(\n",
        "            nn.Linear(256, 128), nn.ReLU(), nn.Linear(128, 2), nn.Softmax(dim=1)\n",
        "        )\n",
        "        self.classifier = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x_img, x_graph_all, edge_index, batch_indices):\n",
        "        f1 = self.branch1(x_img)\n",
        "        f2_all = self.branch2(x_graph_all, edge_index)\n",
        "        f2 = f2_all[batch_indices]\n",
        "        combined = torch.stack((f1, f2), dim=1)\n",
        "        attn_weights = self.attn(torch.cat((f1, f2), dim=1)).unsqueeze(2)\n",
        "        fused = (combined * attn_weights).sum(dim=1)\n",
        "        return self.classifier(fused)\n"
      ],
      "metadata": {
        "id": "DWwjxVGskPAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    data, labels = load_pavia_university()\n",
        "    data = preprocess(data)\n",
        "    data = apply_pca(data, num_components=30)\n",
        "    patches, targets, _ = extract_patches(data, labels, patch_size=7)\n",
        "\n",
        "    num_samples = patches.shape[0]\n",
        "    le = LabelEncoder()\n",
        "    targets = le.fit_transform(targets)\n",
        "\n",
        "    x_graph = patches[:, patches.shape[1] // 2, patches.shape[2] // 2, :]\n",
        "    scaler = StandardScaler()\n",
        "    x_graph = torch.tensor(scaler.fit_transform(x_graph), dtype=torch.float32).to(device)\n",
        "\n",
        "    adj = kneighbors_graph(x_graph.cpu().numpy(), n_neighbors=8, mode='connectivity')\n",
        "    edge_index, _ = dense_to_sparse(torch.tensor(adj.toarray(), dtype=torch.float))\n",
        "    edge_index = edge_index.to(device).long()\n",
        "\n",
        "\n",
        "    x_img = torch.tensor(patches, dtype=torch.float32).to(device)\n",
        "    y = torch.tensor(targets, dtype=torch.long).to(device)\n",
        "    train_idx, test_idx = train_test_split(np.arange(num_samples), test_size=0.3, random_state=42, stratify=targets)\n",
        "    train_dataset = HSIDataset(x_img[train_idx], x_graph[train_idx], y[train_idx])\n",
        "    test_dataset = HSIDataset(x_img[test_idx], x_graph[test_idx], y[test_idx])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "    model = DualBranchFusion(in_channels=30, num_classes=len(np.unique(targets))).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    x_graph_all = x_graph\n",
        "    model.train()\n",
        "    for epoch in range(50):\n",
        "        total_loss = 0\n",
        "        for x_img_batch, xg_batch, y_batch in train_loader:\n",
        "            x_img_batch, xg_batch, y_batch = x_img_batch.to(device), xg_batch.to(device), y_batch.to(device)\n",
        "            batch_indices = torch.where((xg_batch[:, None] == x_graph_all).all(dim=2))[1]\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x_img_batch, x_graph_all, edge_index, batch_indices)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        scheduler.step()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTS8lWd-kO-j",
        "outputId": "2aff3217-088e-488a-ab27-681c8c9bb4dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 99.5266\n",
            "Epoch 2, Loss: 12.4193\n",
            "Epoch 3, Loss: 6.7023\n",
            "Epoch 4, Loss: 4.7907\n",
            "Epoch 5, Loss: 12.4503\n",
            "Epoch 6, Loss: 2.3751\n",
            "Epoch 7, Loss: 0.1471\n",
            "Epoch 8, Loss: 0.0685\n",
            "Epoch 9, Loss: 0.0465\n",
            "Epoch 10, Loss: 0.0245\n",
            "Epoch 11, Loss: 0.0179\n",
            "Epoch 12, Loss: 21.9294\n",
            "Epoch 13, Loss: 2.6667\n",
            "Epoch 14, Loss: 0.7789\n",
            "Epoch 15, Loss: 0.4693\n",
            "Epoch 16, Loss: 1.1668\n",
            "Epoch 17, Loss: 9.0933\n",
            "Epoch 18, Loss: 1.2520\n",
            "Epoch 19, Loss: 1.3619\n",
            "Epoch 20, Loss: 1.1873\n",
            "Epoch 21, Loss: 0.1147\n",
            "Epoch 22, Loss: 0.0207\n",
            "Epoch 23, Loss: 0.0098\n",
            "Epoch 24, Loss: 0.0060\n",
            "Epoch 25, Loss: 0.0053\n",
            "Epoch 26, Loss: 0.0040\n",
            "Epoch 27, Loss: 0.0030\n",
            "Epoch 28, Loss: 0.0035\n",
            "Epoch 29, Loss: 0.0020\n",
            "Epoch 30, Loss: 0.0017\n",
            "Epoch 31, Loss: 0.0011\n",
            "Epoch 32, Loss: 0.0012\n",
            "Epoch 33, Loss: 0.0015\n",
            "Epoch 34, Loss: 0.0014\n",
            "Epoch 35, Loss: 0.0005\n",
            "Epoch 36, Loss: 0.0003\n",
            "Epoch 37, Loss: 8.4614\n",
            "Epoch 38, Loss: 1.7934\n",
            "Epoch 39, Loss: 0.1433\n",
            "Epoch 40, Loss: 0.0556\n",
            "Epoch 41, Loss: 0.0197\n",
            "Epoch 42, Loss: 0.0058\n",
            "Epoch 43, Loss: 0.0062\n",
            "Epoch 44, Loss: 0.0042\n",
            "Epoch 45, Loss: 0.0029\n",
            "Epoch 46, Loss: 0.0025\n",
            "Epoch 47, Loss: 0.0022\n",
            "Epoch 48, Loss: 0.0015\n",
            "Epoch 49, Loss: 0.0012\n",
            "Epoch 50, Loss: 0.0008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for x_img_batch, xg_batch, y_batch in test_loader:\n",
        "            x_img_batch, xg_batch, y_batch = x_img_batch.to(device), xg_batch.to(device), y_batch.to(device)\n",
        "            batch_indices = torch.where((xg_batch[:, None] == x_graph_all).all(dim=2))[1]\n",
        "            outputs = model(x_img_batch, x_graph_all, edge_index, batch_indices)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(y_batch.cpu().numpy())\n",
        "\n",
        "    oa = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "    kappa = cohen_kappa_score(all_labels, all_preds)\n",
        "\n",
        "    print(f\"\\nOverall Accuracy (OA): {oa:.4f}\")\n",
        "    print(f\"F1 Score (Macro): {f1:.4f}\")\n",
        "    print(f\"Cohen's Kappa: {kappa:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AT9m1SOHmsta",
        "outputId": "1a5aad0a-3549-448a-c17e-22b3d7164ad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Overall Accuracy (OA): 0.9994\n",
            "F1 Score (Macro): 0.9990\n",
            "Cohen's Kappa: 0.9992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"dual_branch_hsi_model.pth\")\n",
        "print(\"Model saved to dual_branch_hsi_model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmGr98Qi4OJH",
        "outputId": "35fb2345-2593-4f9b-d423-1ab269ba0c5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to dual_branch_hsi_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4iHrvYM34msc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}